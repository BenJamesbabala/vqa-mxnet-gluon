{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Visual Question Answering in gluon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "This is a notebook for implementing visual question answering in gluon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import mxnet as mx\n",
    "import mxnet.ndarray as F\n",
    "import mxnet.gluon as gluon\n",
    "from mxnet.gluon import nn\n",
    "from mxnet import autograd\n",
    "import bisect\n",
    "from IPython.core.display import display, HTML\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "import os\n",
    "from mxnet.test_utils import download\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## The VQA dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "In the VQA dataset, for each sample, there is one image and one question. The label is the answer for the question regarding the image. You can download the VQA1.0 dataset from <a href=\"http://www.visualqa.org/vqa_v1_download.html\">VQA</a>. \n",
    "\n",
    "\n",
    "You need to preprocess the data:(1) Extract the samples from original json files. (2) Filter the samples giving top k answers(k can be 1000, 2000...). \n",
    "\n",
    "Usually people use pretrained models to extract vector features from the image and question: Resnet152 for image and skipthought for question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Data Iterator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The inputs of the data iterator are extracted image and question features. At each step, the data iterator will return a data batch list: question data batch and image data batch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class VQAtrainIter(mx.io.DataIter):\n",
    "    def __init__(self, img, sentences, answer, batch_size, buckets=None, invalid_label=-1,\n",
    "                 text_name='text', img_name = 'image', label_name='softmax_label', dtype='float32', layout='NTC'):\n",
    "        super(VQAtrainIter, self).__init__()\n",
    "        if not buckets:\n",
    "            buckets = [i for i, j in enumerate(np.bincount([len(s) for s in sentences]))\n",
    "                       if j >= batch_size]\n",
    "        buckets.sort()\n",
    "\n",
    "        ndiscard = 0\n",
    "        self.data = [[] for _ in buckets]\n",
    "        for i in range(len(sentences)):\n",
    "            buck = bisect.bisect_left(buckets, len(sentences[i]))\n",
    "            if buck == len(buckets):\n",
    "                ndiscard += 1\n",
    "                continue\n",
    "            buff = np.full((buckets[buck],), invalid_label, dtype=dtype)\n",
    "            buff[:len(sentences[i])] = sentences[i]\n",
    "            self.data[buck].append(buff)\n",
    "\n",
    "        self.data = [np.asarray(i, dtype=dtype) for i in self.data]\n",
    "        self.answer = answer\n",
    "        self.img = img\n",
    "        print(\"WARNING: discarded %d sentences longer than the largest bucket.\"%ndiscard)\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.buckets = buckets\n",
    "        self.text_name = text_name\n",
    "        self.img_name = img_name\n",
    "        self.label_name = label_name\n",
    "        self.dtype = dtype\n",
    "        self.invalid_label = invalid_label\n",
    "        self.nd_text = []\n",
    "        self.nd_img = []\n",
    "        self.ndlabel = []\n",
    "        self.major_axis = layout.find('N')\n",
    "        self.default_bucket_key = max(buckets)\n",
    "\n",
    "        if self.major_axis == 0:\n",
    "            self.provide_data = [(text_name, (batch_size, self.default_bucket_key)),\n",
    "                                 (img_name, (batch_size, self.default_bucket_key))]\n",
    "            self.provide_label = [(label_name, (batch_size, self.default_bucket_key))]\n",
    "        elif self.major_axis == 1:\n",
    "            self.provide_data = [(text_name, (self.default_bucket_key, batch_size)),\n",
    "                                 (img_name, (self.default_bucket_key, batch_size))]\n",
    "            self.provide_label = [(label_name, (self.default_bucket_key, batch_size))]\n",
    "        else:\n",
    "            raise ValueError(\"Invalid layout %s: Must by NT (batch major) or TN (time major)\")\n",
    "\n",
    "        self.idx = []\n",
    "        for i, buck in enumerate(self.data):\n",
    "            self.idx.extend([(i, j) for j in range(0, len(buck) - batch_size + 1, batch_size)])\n",
    "        self.curr_idx = 0\n",
    "\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.curr_idx = 0\n",
    "        self.nd_text = []\n",
    "        self.nd_img = []\n",
    "        self.ndlabel = []\n",
    "        for buck in self.data:\n",
    "            label = np.empty_like(buck.shape[0])\n",
    "            label = self.answer\n",
    "            self.nd_text.append(mx.ndarray.array(buck, dtype=self.dtype))\n",
    "            self.nd_img.append(mx.ndarray.array(self.img, dtype=self.dtype))\n",
    "            self.ndlabel.append(mx.ndarray.array(label, dtype=self.dtype))\n",
    "\n",
    "    def next(self):\n",
    "        if self.curr_idx == len(self.idx):\n",
    "            raise StopIteration\n",
    "        i, j = self.idx[self.curr_idx]\n",
    "        self.curr_idx += 1\n",
    "\n",
    "        if self.major_axis == 1:\n",
    "            img = self.nd_img[i][j:j + self.batch_size].T\n",
    "            text = self.nd_text[i][j:j + self.batch_size].T\n",
    "            label = self.ndlabel[i][j:j+self.batch_size]\n",
    "        else:\n",
    "            img = self.nd_img[i][j:j + self.batch_size]\n",
    "            text = self.nd_text[i][j:j + self.batch_size]\n",
    "            label = self.ndlabel[i][j:j+self.batch_size]\n",
    "        \n",
    "        data = [text, img]\n",
    "        return mx.io.DataBatch(data, [label],\n",
    "                         bucket_key=self.buckets[i],\n",
    "                         provide_data=[(self.text_name, text.shape),(self.img_name, img.shape)],\n",
    "                         provide_label=[(self.label_name, label.shape)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Here we will use 1/10 of the VQA training data and 1/100 of the validation data to explain the model since the data is very large. We extract the image feature from ResNet-152, text feature from GNMT encoder. We have 21537 training samples and 1044 validation samples. Image feature is a 2048-dim vector. Question feature is a 1048-dim vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "demo = False\n",
    "dataset_files = {'train': ('train_question.npz','train_img.npz','train_ans.npz'),\n",
    "                 'validation': ('val_question.npz','val_img.npz','val_ans.npz'),\n",
    "                'test':('test_question_id.npz','test_question.npz','test_img_id.npz','test_img.npz','atoi.json','test_question_txt.json')}\n",
    "if demo:\n",
    "    train_q, train_i, train_a = dataset_files['validation']\n",
    "else:\n",
    "    train_q, train_i, train_a = dataset_files['train']\n",
    "val_q, val_i, val_a = dataset_files['validation']\n",
    "\n",
    "url_format = 'https://apache-mxnet.s3-accelerate.amazonaws.com/gluon/dataset/VQA-notebook/{}'\n",
    "if not os.path.exists(train_q):\n",
    "    logging.info('Downloading training dataset.')\n",
    "    download(url_format.format(train_q),overwrite=True)\n",
    "    download(url_format.format(train_i),overwrite=True)\n",
    "    download(url_format.format(train_a),overwrite=True)\n",
    "if not os.path.exists(val_q):\n",
    "    logging.info('Downloading validation dataset.')\n",
    "    download(url_format.format(val_q),overwrite=True)\n",
    "    download(url_format.format(val_i),overwrite=True)\n",
    "    download(url_format.format(val_a),overwrite=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: discarded 0 sentences longer than the largest bucket.\n",
      "WARNING: discarded 0 sentences longer than the largest bucket.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "layout = 'NT'\n",
    "bucket = [1024]\n",
    "\n",
    "if demo:\n",
    "    train_question = np.load(\"val_question.npz\")['x']\n",
    "    val_question = np.load(\"val_question.npz\")['x']\n",
    "    train_ans = np.load(\"val_ans.npz\")['x']\n",
    "    val_ans = np.load(\"val_ans.npz\")['x']\n",
    "    train_img = np.load(\"val_img.npz\")['x']\n",
    "    val_img = np.load(\"val_img.npz\")['x']\n",
    "else:\n",
    "    train_question = np.load(\"train_question.npz\")['x']\n",
    "    val_question = np.load(\"val_question.npz\")['x']\n",
    "    train_ans = np.load(\"train_ans.npz\")['x']\n",
    "    val_ans = np.load(\"val_ans.npz\")['x']\n",
    "    train_img = np.load(\"train_img.npz\")['x']\n",
    "    val_img = np.load(\"val_img.npz\")['x']\n",
    "\n",
    "\n",
    "data_train  = VQAtrainIter(train_img, train_question, train_ans, batch_size, buckets = bucket,layout=layout)\n",
    "data_eva = VQAtrainIter(val_img, val_question, val_ans, batch_size, buckets = bucket,layout=layout) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Define the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "gluon.Block is the basic building block of models. If any operator is not defined under gluon, you can use mxnet.ndarray operators to subsititude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class Net(gluon.Block):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Net, self).__init__(**kwargs)\n",
    "        with self.name_scope():\n",
    "            # layers created in name_scope will inherit name space\n",
    "            # from parent layer.\n",
    "            self.bn = nn.BatchNorm()\n",
    "            self.dropout = nn.Dropout(0.3)\n",
    "            self.fc1 = nn.Dense(8192,activation=\"relu\")\n",
    "            self.fc2 = nn.Dense(1000)\n",
    "            \n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = F.L2Normalization(x[0])\n",
    "        x2 = F.L2Normalization(x[1])\n",
    "        z = F.concat(x1,x2,dim=1)\n",
    "        z = self.fc1(z)\n",
    "        z = self.bn(z)\n",
    "        z = self.dropout(z)\n",
    "        z = self.fc2(z)\n",
    "        return z\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Initialize the Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ctx = mx.gpu(2)\n",
    "net = Net()\n",
    "# Initialize on CPU. Replace with `mx.gpu(0)`, or `[mx.gpu(0), mx.gpu(1)]`,\n",
    "# etc to use one or more GPUs.\n",
    "net.collect_params().initialize(mx.init.Xavier(), ctx=ctx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "loss = gluon.loss.SoftmaxCrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "metric = mx.metric.Accuracy()\n",
    "\n",
    "def evaluate_accuracy(data_iterator, net):\n",
    "    numerator = 0.\n",
    "    denominator = 0.\n",
    "    \n",
    "    data_iterator.reset()\n",
    "    for i, batch in enumerate(data_iterator):\n",
    "        with autograd.record():\n",
    "            data1 = batch.data[0].as_in_context(ctx)\n",
    "            data2 = batch.data[1].as_in_context(ctx)\n",
    "            data = [data1,data2]\n",
    "            label = batch.label[0].as_in_context(ctx)\n",
    "            #label_one_hot = nd.one_hot(label, 10)\n",
    "            output = net(data)\n",
    "        \n",
    "        metric.update([label], [output])\n",
    "    return metric.get()[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': 0.01})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, batch 0. Moving avg of loss: 7.97375\n",
      "Epoch 0, batch 150. Moving avg of loss: 4.47674059535\n",
      "Epoch 0, batch 300. Moving avg of loss: 3.65895324027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Best validation acc found. Checkpointing...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0. Loss: 3.34125776846, Train_acc 0.453879616477, Eval_acc 0.3779296875\n",
      "Epoch 1, batch 0. Moving avg of loss: 3.36886\n",
      "Epoch 1, batch 150. Moving avg of loss: 2.36092440299\n",
      "Epoch 1, batch 300. Moving avg of loss: 2.54908521974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Best validation acc found. Checkpointing...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1. Loss: 2.49631016487, Train_acc 0.493607954545, Eval_acc 0.44968580163\n",
      "Epoch 2, batch 0. Moving avg of loss: 0.704168\n",
      "Epoch 2, batch 150. Moving avg of loss: 1.49337662733\n",
      "Epoch 2, batch 300. Moving avg of loss: 1.97082520201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Best validation acc found. Checkpointing...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2. Loss: 1.98933175847, Train_acc 0.527595288826, Eval_acc 0.491493055556\n",
      "Epoch 3, batch 0. Moving avg of loss: 2.01391\n",
      "Epoch 3, batch 150. Moving avg of loss: 1.47874832342\n",
      "Epoch 3, batch 300. Moving avg of loss: 1.65094811728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Best validation acc found. Checkpointing...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3. Loss: 1.65167601917, Train_acc 0.560247247869, Eval_acc 0.525550956157\n",
      "Epoch 4, batch 0. Moving avg of loss: 1.7884\n",
      "Epoch 4, batch 150. Moving avg of loss: 1.24198134016\n",
      "Epoch 4, batch 300. Moving avg of loss: 1.3355012858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Best validation acc found. Checkpointing...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4. Loss: 1.34260104669, Train_acc 0.589302201705, Eval_acc 0.558132900281\n",
      "Epoch 5, batch 0. Moving avg of loss: 2.91607\n",
      "Epoch 5, batch 150. Moving avg of loss: 1.34103775143\n",
      "Epoch 5, batch 300. Moving avg of loss: 1.13397172157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Best validation acc found. Checkpointing...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5. Loss: 1.08647407867, Train_acc 0.614916252367, Eval_acc 0.587485923423\n",
      "Epoch 6, batch 0. Moving avg of loss: 0.992226\n",
      "Epoch 6, batch 150. Moving avg of loss: 0.797239733449\n",
      "Epoch 6, batch 300. Moving avg of loss: 0.840630521218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Best validation acc found. Checkpointing...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6. Loss: 0.919299564252, Train_acc 0.637853845373, Eval_acc 0.613185796523\n",
      "Epoch 7, batch 0. Moving avg of loss: 1.13513\n",
      "Epoch 7, batch 150. Moving avg of loss: 0.756738901317\n",
      "Epoch 7, batch 300. Moving avg of loss: 0.698150393895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Best validation acc found. Checkpointing...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7. Loss: 0.719230582393, Train_acc 0.658020019531, Eval_acc 0.636252520161\n",
      "Epoch 8, batch 0. Moving avg of loss: 0.682457\n",
      "Epoch 8, batch 150. Moving avg of loss: 0.580595296121\n",
      "Epoch 8, batch 300. Moving avg of loss: 0.604947883405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Best validation acc found. Checkpointing...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8. Loss: 0.587828519675, Train_acc 0.67584536774, Eval_acc 0.65647069209\n",
      "Epoch 9, batch 0. Moving avg of loss: 1.2247\n",
      "Epoch 9, batch 150. Moving avg of loss: 0.594253024098\n",
      "Epoch 9, batch 300. Moving avg of loss: 0.515729901345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Best validation acc found. Checkpointing...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9. Loss: 0.546512375941, Train_acc 0.691290838068, Eval_acc 0.674431728957\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "moving_loss = 0.\n",
    "best_eva = 0\n",
    "for e in range(epochs):\n",
    "    data_train.reset()\n",
    "    for i, batch in enumerate(data_train):\n",
    "        data1 = batch.data[0].as_in_context(ctx)\n",
    "        data2 = batch.data[1].as_in_context(ctx)\n",
    "        data = [data1,data2]\n",
    "        label = batch.label[0].as_in_context(ctx)\n",
    "        with autograd.record():\n",
    "            output = net(data)\n",
    "            cross_entropy = loss(output, label)\n",
    "            cross_entropy.backward()\n",
    "        trainer.step(data[0].shape[0])\n",
    "        \n",
    "        ##########################\n",
    "        #  Keep a moving average of the losses\n",
    "        ##########################\n",
    "        if i == 0:\n",
    "            moving_loss = np.mean(cross_entropy.asnumpy()[0])\n",
    "        else:\n",
    "            moving_loss = .99 * moving_loss + .01 * np.mean(cross_entropy.asnumpy()[0])\n",
    "        if i % 150 == 0:\n",
    "            print(\"Epoch %s, batch %s. Moving avg of loss: %s\" % (e, i, moving_loss))   \n",
    "    eva_accuracy = evaluate_accuracy(data_eva, net)\n",
    "    train_accuracy = evaluate_accuracy(data_train, net)\n",
    "    print(\"Epoch %s. Loss: %s, Train_acc %s, Eval_acc %s\" % (e, moving_loss, train_accuracy, eva_accuracy))\n",
    "    if eva_accuracy > best_eva:\n",
    "            best_eva = eva_accuracy\n",
    "            logging.info('Best validation acc found. Checkpointing...')\n",
    "            net.save_params('vqa-mlp-%d.params'%(e))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try it out!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can try it on test data. Here we have 10 test samples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:downloaded https://apache-mxnet.s3-accelerate.amazonaws.com/gluon/dataset/VQA-notebook/test_question_txt.json into test_question_txt.json successfully\n"
     ]
    }
   ],
   "source": [
    "test = True\n",
    "if test:\n",
    "    test_q_id, test_q, test_i_id, test_i, atoi,text = dataset_files['test']\n",
    "\n",
    "if test and not os.path.exists(test_q):     \n",
    "    logging.info('Downloading test dataset.')\n",
    "    download(url_format.format(test_q_id),overwrite=True)\n",
    "    download(url_format.format(test_q),overwrite=True)\n",
    "    download(url_format.format(test_i_id),overwrite=True)\n",
    "    download(url_format.format(test_i),overwrite=True)\n",
    "    download(url_format.format(atoi),overwrite=True)\n",
    "download(url_format.format(text),overwrite=True)\n",
    "\n",
    "if test:\n",
    "    test_question = np.load(\"test_question.npz\")['x']\n",
    "    test_img = np.load(\"test_img.npz\")['x']\n",
    "    test_question_id = np.load(\"test_question_id.npz\")['x']\n",
    "    test_img_id = np.load(\"test_img_id.npz\")['x']\n",
    "    #atoi = np.load(\"atoi.json\")['x']\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We pass the test data iterator to the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: discarded 0 sentences longer than the largest bucket.\n"
     ]
    }
   ],
   "source": [
    "data_test = VQAtrainIter(test_img, test_question, np.zeros((test_img.shape[0],1)), 10, buckets = bucket,layout=layout)\n",
    "for i, batch in enumerate(data_test):\n",
    "    with autograd.record():\n",
    "        data1 = batch.data[0].as_in_context(ctx)\n",
    "        data2 = batch.data[1].as_in_context(ctx)\n",
    "        data = [data1,data2]\n",
    "        #label = batch.label[0].as_in_context(ctx)\n",
    "        #label_one_hot = nd.one_hot(label, 10)\n",
    "        output = net(data)\n",
    "output = np.argmax(output.asnumpy(), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Downloading training dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is this place?\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "failed to open https://apache-mxnet.s3-accelerate.amazonaws.com/gluon/dataset/VQA-notebook/COCO_test2015_000000576922.jpg",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-0b6847b5455b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test_images/'\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mimage_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Downloading training dataset.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/mxnet-0.10.1-py2.7.egg/mxnet/test_utils.pyc\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(url, fname, dirname, overwrite)\u001b[0m\n\u001b[1;32m    967\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 969\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"failed to open %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    970\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: failed to open https://apache-mxnet.s3-accelerate.amazonaws.com/gluon/dataset/VQA-notebook/COCO_test2015_000000576922.jpg"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "question = json.load(open(text))\n",
    "print(\"Question:\", question[idx])\n",
    "image_name = 'COCO_test2015_' + str(int(test_img_id[idx])).zfill(12)+'.jpg'\n",
    "if not os.path.exists(image_name):\n",
    "    logging.info('Downloading training dataset.')\n",
    "    download(url_format.format('test_images/'+image_name),overwrite=True)\n",
    "from IPython.display import Image\n",
    "Image(filename=image_name) \n",
    "\n",
    "dataset = json.load(open('atoi.json'))\n",
    "ans = dataset['ix_to_ans'][str(output[idx]+1)]\n",
    "print(\"Answer:\", ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
